{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4319c09-3e10-47e5-b10b-f6f5400e6bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "357fcf92-3a86-4d99-bf19-e63beef0e788",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'qa_dataset_time_sort.json'\n",
    "qa_dataset = json.load(open(path, 'r', encoding='utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40d299ff-c160-4f6b-8d4e-57cc253dfd99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total question numbers :24464\n"
     ]
    }
   ],
   "source": [
    "print(\"Total question numbers :\" + str(len(qa_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c471ad3-d247-4f7f-842c-b6a652ad8a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "filePath ='Domain_qa_dataset/'\n",
    "indusAndTech = []\n",
    "for domain, t in [('industrials','train'),('industrials','dev'),('industrials','test'),('technology','train'),('technology','dev'),('technology','test')]:\n",
    "    file = 'qa_{}_{}.json'.format(domain, t)\n",
    "    f = json.load(open(os.path.join(filePath, file)))\n",
    "    indusAndTech += f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf9f6c32-7688-492d-b1b8-b4f31a0d011e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indus & Tech question numbers :5946\n",
      "All other domain question number :18518\n"
     ]
    }
   ],
   "source": [
    "print(\"Indus & Tech question numbers :\" + str(len(indusAndTech)))\n",
    "print(\"All other domain question number :\" + str(len(qa_dataset) - len(indusAndTech)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54b14c72-be04-430c-a5c4-a76519956bc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5946"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indusAndtech_qid_list = []\n",
    "for qa in indusAndTech:\n",
    "    indusAndtech_qid_list.append(qa['qid'])\n",
    "len(indusAndtech_qid_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e98ff47f-84ae-4a81-8861-4dcf521c0f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20674"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allOtherDomain = []\n",
    "for qa in qa_dataset:\n",
    "    if qa['qid'] not in indusAndtech_qid_list:\n",
    "        allOtherDomain.append(qa)\n",
    "len(allOtherDomain)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6569628e-03b2-4027-bc7f-792189b9d434",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------------------\n",
    "remove duplicate qid in the domain dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce33e1c6-e3eb-4f8e-942c-e9b3b0efc5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_domain_dataset(domain_Name):\n",
    "    l = []\n",
    "    filePath ='Domain_qa_dataset/'\n",
    "    for domain, t in [(domain_Name,'train'),(domain_Name,'dev'),(domain_Name,'test')]:\n",
    "        file = 'qa_{}_{}.json'.format(domain, t)\n",
    "        f = json.load(open(os.path.join(filePath, file)))\n",
    "        print('file\":', file, \"len:\", len(f))\n",
    "        l += f\n",
    "    return l\n",
    "\n",
    "def to_qid_list(dataset):\n",
    "    qid_list = []\n",
    "    for qa in dataset:\n",
    "        qid_list.append(qa['qid'])\n",
    "    return qid_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a20d5620-0eeb-4e07-9ec8-3313d46e7660",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_duplicate_q(domain): \n",
    "    domain_dataset = read_domain_dataset(domain)\n",
    "    domain_qid_list = to_qid_list(domain_dataset)\n",
    "    print(len(domain_dataset), len(domain_qid_list), len(set(domain_qid_list)))\n",
    "    without_duplicate_dataset = []\n",
    "    qid_included = []\n",
    "    for q in domain_dataset:\n",
    "        if q['qid'] not in qid_included:\n",
    "            without_duplicate_dataset.append(q)\n",
    "            qid_included.append(q['qid'])\n",
    "    print(len(without_duplicate_dataset))\n",
    "    return without_duplicate_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca2e10f6-a2bf-40f9-a004-9c4483745519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file\": qa_consumer_train.json len: 2619\n",
      "file\": qa_consumer_dev.json len: 327\n",
      "file\": qa_consumer_test.json len: 328\n",
      "3274 3274 2155\n",
      "2155\n"
     ]
    }
   ],
   "source": [
    "consumer_without_duplicate = remove_duplicate_q('consumer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7911fd12-39b9-4afb-a3b5-a1d996972b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def domain_train_test_split(domain):\n",
    "    print(int(len(domain) * 0.8), int(len(domain) * 0.1), len(domain) - int(len(domain) * 0.8)- int(len(domain) * 0.1))\n",
    "    domain_train = domain[:int(len(domain) * 0.8)]\n",
    "    domain_dev = domain[int(len(domain) * 0.8):int(len(domain) * 0.8)+int(len(domain) * 0.1)]\n",
    "    domain_test = domain[int(len(domain) * 0.8)+int(len(domain) * 0.1):]\n",
    "    print(len(domain_train), len(domain_dev), len(domain_test))\n",
    "    return domain_train, domain_dev, domain_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fdd5d0-0f54-4840-9100-0686c230da86",
   "metadata": {},
   "outputs": [],
   "source": [
    "consumer_train, consumer_dev, consumer_test = domain_train_test_split(consumer_without_duplicate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "210c91f9-1383-40c7-871e-f42cd3838c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_train_dev_test_files(domain, train, dev, test):\n",
    "    json.dump(train, open('Domain_without_duplicate_dataset/qa_{}_train.json'.format(domain), 'w', encoding='utf8'))\n",
    "    json.dump(dev, open('Domain_without_duplicate_dataset/qa_{}_dev.json'.format(domain), 'w', encoding='utf8'))\n",
    "    json.dump(test, open('Domain_without_duplicate_dataset/qa_{}_test.json'.format(domain), 'w', encoding='utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "38a989e9-51be-425c-862a-a69a3999a579",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file\": qa_consumer_train.json len: 2619\n",
      "file\": qa_consumer_dev.json len: 327\n",
      "file\": qa_consumer_test.json len: 328\n",
      "3274 3274 2155\n",
      "2155\n",
      "1724 215 216\n",
      "1724 215 216\n",
      "file\": qa_healthcare_train.json len: 1916\n",
      "file\": qa_healthcare_dev.json len: 239\n",
      "file\": qa_healthcare_test.json len: 240\n",
      "2395 2395 1512\n",
      "1512\n",
      "1209 151 152\n",
      "1209 151 152\n",
      "file\": qa_industrials_train.json len: 2240\n",
      "file\": qa_industrials_dev.json len: 280\n",
      "file\": qa_industrials_test.json len: 281\n",
      "2801 2801 1823\n",
      "1823\n",
      "1458 182 183\n",
      "1458 182 183\n",
      "file\": qa_technology_train.json len: 2516\n",
      "file\": qa_technology_dev.json len: 314\n",
      "file\": qa_technology_test.json len: 315\n",
      "3145 3145 1968\n",
      "1968\n",
      "1574 196 198\n",
      "1574 196 198\n"
     ]
    }
   ],
   "source": [
    "for domain in ['consumer', 'healthcare', 'industrials', 'technology']:\n",
    "    domain_without_duplicate = remove_duplicate_q(domain)\n",
    "    domain_train, domain_dev, domain_test = domain_train_test_split(domain_without_duplicate)\n",
    "    drop_train_dev_test_files(domain, domain_train, domain_dev, domain_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c235027-c84f-4d9d-ac3e-dffa65dbe7b8",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------\n",
    "\n",
    "### Add sentiment template to domain dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "405a8855-4247-4718-8c96-29261c36e298",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package names to /home/yingjie/nltk_data...\n",
      "[nltk_data]   Package names is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/yingjie/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package state_union to\n",
      "[nltk_data]     /home/yingjie/nltk_data...\n",
      "[nltk_data]   Package state_union is already up-to-date!\n",
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     /home/yingjie/nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n",
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/yingjie/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/yingjie/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/yingjie/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/yingjie/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /home/yingjie/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/yingjie/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import nltk\n",
    "import svgling\n",
    "import os\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "nltk.download([\n",
    "    \"names\",\n",
    "    \"stopwords\",\n",
    "    \"state_union\",\n",
    "    \"twitter_samples\",\n",
    "    \"movie_reviews\",\n",
    "    \"averaged_perceptron_tagger\",\n",
    "    \"vader_lexicon\",\n",
    "    \"punkt\",\n",
    "    \"maxent_ne_chunker\",\n",
    "    \"words\",\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "722cbc3d-539b-4fe5-af8f-36ee1e5a0a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_word(sentence, polarity='positive'):\n",
    "    senti = SentimentIntensityAnalyzer()\n",
    "    senti_score = []\n",
    "    if polarity=='positive':\n",
    "        for word in sentence.split():\n",
    "            senti_score.append(senti.polarity_scores(word)['compound'])\n",
    "        if max(senti_score) == 0:\n",
    "            prompt = sentence.split()[random.randint(0, len(sentence.split())-1)]\n",
    "        else:\n",
    "            max_index = senti_score.index(max(senti_score))\n",
    "            prompt = sentence.split()[max_index]\n",
    "    elif polarity=='negative':\n",
    "        for word in sentence.split():\n",
    "            senti_score.append(senti.polarity_scores(word)['compound'])\n",
    "        if min(senti_score) == 0:\n",
    "            prompt = sentence.split()[random.randint(0, len(sentence.split())-1)]\n",
    "        else:\n",
    "            min_index = senti_score.index(min(senti_score))\n",
    "            prompt = sentence.split()[min_index]\n",
    "    else:\n",
    "        prompt = sentence.split()[random.randint(0, len(sentence.split())-1)]\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f56d0db-c981-4320-a08e-307257996426",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sentiment_template_for_domain(qa_dataset):\n",
    "    senti = SentimentIntensityAnalyzer()\n",
    "    for qa in qa_dataset:\n",
    "        query = qa['question']\n",
    "        (start, end) = qa['answer']\n",
    "        answer_text = qa['context'][start:end]\n",
    "        context_list = qa['context'].split('. ')\n",
    "        for sentence in context_list:\n",
    "            if answer_text in sentence:\n",
    "                break\n",
    "\n",
    "        # sentiment\n",
    "\n",
    "        query_sentiment = senti.polarity_scores(query)['compound']\n",
    "        if query_sentiment <= -0.5:\n",
    "            query_sentiment = 'very negative'\n",
    "            word = get_sentiment_word(sentence, polarity='negative')\n",
    "        elif query_sentiment< 0:\n",
    "            query_sentiment = 'negative'\n",
    "            word = get_sentiment_word(sentence, polarity='negative')\n",
    "        elif query_sentiment== 0:\n",
    "            query_sentiment = 'none'\n",
    "            word = get_sentiment_word(sentence, polarity='none')\n",
    "        elif query_sentiment<= 0.5:\n",
    "            query_sentiment = 'positive'\n",
    "            word = get_sentiment_word(sentence, polarity='positive')\n",
    "        else:\n",
    "            query_sentiment = 'very positive'\n",
    "            word = get_sentiment_word(sentence, polarity='positive')\n",
    "        template_02 = 'The sentiment of this question is {}, you need to look for {}'.format(query_sentiment, word)\n",
    "\n",
    "        template = [template_02,]\n",
    "\n",
    "        qa['template'] = template\n",
    "        \n",
    "    return qa_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb15403b-9df6-4df5-a121-08a62149d85b",
   "metadata": {},
   "source": [
    "### Iterate through all domain files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29297e16-987d-4762-9a90-4295a1305699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['qa_technology_train.json',\n",
       " 'qa_industrials_dev.json',\n",
       " 'qa_industrials_test.json',\n",
       " 'qa_technology_dev.json',\n",
       " '.ipynb_checkpoints',\n",
       " 'qa_technology_test.json',\n",
       " 'qa_healthcare_test.json',\n",
       " 'qa_healthcare_dev.json',\n",
       " 'qa_consumer_test.json',\n",
       " 'qa_healthcare_train.json',\n",
       " 'qa_industrials_train.json',\n",
       " 'qa_consumer_dev.json',\n",
       " 'qa_consumer_train.json']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "without_template_path = 'Domain_without_duplicate_dataset/without_template/'\n",
    "fileList = os.listdir(without_template_path)\n",
    "fileList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e175abf-d9c7-4340-beff-6677b0b05963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "technology train\n",
      "industrials dev\n",
      "industrials test\n",
      "technology dev\n",
      "technology test\n",
      "healthcare test\n",
      "healthcare dev\n",
      "consumer test\n",
      "healthcare train\n",
      "industrials train\n",
      "consumer dev\n",
      "consumer train\n"
     ]
    }
   ],
   "source": [
    "for file in fileList:\n",
    "    if file[0] != '.':\n",
    "        domain = file.split('_')[1]\n",
    "        t = file.split('_')[2][:-5]\n",
    "        print(domain, t)\n",
    "        f = json.load(open(os.path.join(without_template_path, file)))\n",
    "        withSentiment = generate_sentiment_template_for_domain(f)\n",
    "        json.dump(withSentiment, open('Domain_without_duplicate_dataset/sentiment_template/qa_{}_{}.json'.format(domain, t), 'w', encoding='utf8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfce4afa-471e-48df-9423-1e7d0367a7e7",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "source": [
    "# ---------------------------------------------------------------------\n",
    "\n",
    "### Add phrase template to domain dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "322b8601-3e0d-49ac-8b55-ef15a5305036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_phrase_template_for_domain(qa_dataset):\n",
    "    pattern = \"\"\"\n",
    "        NP: {<JJ>+<NN>+}\n",
    "        NPs: {<JJ>+<NNS>+}\n",
    "        Ns: {<NN>+<NN>+}\n",
    "        \"\"\"\n",
    "    pattenParse = nltk.RegexpParser(pattern)\n",
    "\n",
    "    # count=0\n",
    "    for qa in qa_dataset:\n",
    "        query = qa['question']\n",
    "        (start, end) = qa['answer']\n",
    "        answer_text = qa['context'][start:end]\n",
    "        context_list = qa['context'].split('. ')\n",
    "\n",
    "        tokens = nltk.word_tokenize(query)\n",
    "        tagged = nltk.pos_tag(tokens)\n",
    "        cs = pattenParse.parse(tagged)\n",
    "        phrase_template = '\"'\n",
    "        word_template = '\"'\n",
    "        candidates = []\n",
    "        for i in cs:\n",
    "            if type(i) != tuple: \n",
    "                for word in i:\n",
    "                    phrase_template += word[0]+' ' \n",
    "                phrase_template += ', '\n",
    "                # break\n",
    "            elif i[1] == 'JJ' or i[1] == 'NN' or i[1] == 'NNS':\n",
    "                candidates.append(i[0])\n",
    "        phrase_template = phrase_template[:-3]+'\"'\n",
    "\n",
    "        if ', ' in phrase_template:\n",
    "            template_01 = phrase_template + ' are important phrases. '\n",
    "        elif ' ' in phrase_template:\n",
    "            template_01 = phrase_template + ' is an important phrase. '\n",
    "        elif len(phrase_template)>3:\n",
    "            template_01 = phrase_template + ' is an important word. '\n",
    "        else:\n",
    "            template_01 = 'There is no important phrase in this query. '\n",
    "            # template_01 = ' '\n",
    "\n",
    "        if len(candidates)>0:\n",
    "            for candi in range(len(candidates)):\n",
    "                word_template+=candidates[candi]+'\", '\n",
    "                # if candi >= 2:\n",
    "                #     break\n",
    "            word_template = word_template[:-2]\n",
    "\n",
    "            if template_01 == 'There is no important phrase in this query. ':\n",
    "                template_02 = 'And also pay attention to these words: ' + word_template\n",
    "            else:\n",
    "                template_02 = 'And also pay attention to these words: ' + word_template\n",
    "\n",
    "            template = [template_01+template_02,]\n",
    "        else:\n",
    "            template = [template_01,]\n",
    "\n",
    "        qa['template'] = template\n",
    "\n",
    "    return qa_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2287f642-1898-4fd7-969b-d96a51b874c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "industrials dev\n",
      "industrials test\n",
      "consumer test\n",
      "industrials train\n",
      "consumer dev\n",
      "consumer train\n",
      "technology train\n",
      "technology dev\n",
      "technology test\n"
     ]
    }
   ],
   "source": [
    "for file in fileList:\n",
    "    if file[0] != '.':\n",
    "        domain = file.split('_')[1]\n",
    "        t = file.split('_')[2][:-5]\n",
    "        print(domain, t)\n",
    "        f = json.load(open(os.path.join(without_template_path, file)))\n",
    "        withSentiment = generate_phrase_template_for_domain(f)\n",
    "        json.dump(withSentiment, open('Domain_without_duplicate_dataset/wrong_phrase_template/qa_{}_{}.json'.format(domain, t), 'w', encoding='utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8e913199-d3ae-44dc-afbc-02ffe1f481b8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "technology train\n",
      "industrials dev\n",
      "industrials test\n",
      "technology dev\n",
      "technology test\n",
      "healthcare test\n",
      "healthcare dev\n",
      "consumer test\n",
      "healthcare train\n",
      "industrials train\n",
      "consumer dev\n",
      "consumer train\n"
     ]
    }
   ],
   "source": [
    "for file in fileList:\n",
    "    if file[0] != '.':\n",
    "        domain = file.split('_')[1]\n",
    "        t = file.split('_')[2][:-5]\n",
    "        print(domain, t)\n",
    "        f = json.load(open(os.path.join(without_template_path, file)))\n",
    "        withSentiment = generate_phrase_template_for_domain(f)\n",
    "        json.dump(withSentiment, open('Domain_without_duplicate_dataset/phrase_template/qa_{}_{}.json'.format(domain, t), 'w', encoding='utf8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfa2acd-2de1-4537-b1af-6ad09baa6619",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------\n",
    "\n",
    "### Add entity template to domain dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "57891f9b-2606-4c12-992e-b94f4c26850f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c89bcd75-8b8b-486f-836e-14afeb1dd971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_entity_template(one_domain_dataset):\n",
    "    NER = spacy.load('en_core_web_sm')\n",
    "    for qa in one_domain_dataset:\n",
    "        template = []\n",
    "        question = qa['question']\n",
    "        entities = NER(question).ents\n",
    "        if len(entities)>0:\n",
    "            for i in NER(question).ents:\n",
    "                if i.label_ == 'PERSON':\n",
    "                    template_01 = 'This person \"{}\" is menthoned in the question.'.format(i.text)\n",
    "                    template.append(template_01)\n",
    "                elif i.label_ == 'GPE':\n",
    "                    template_01 = 'This country \"{}\" is menthoned in the question.'.format(i.text)\n",
    "                    template.append(template_01)\n",
    "                elif i.label_ == 'ORG':\n",
    "                    template_01 = 'This organization \"{}\" is menthoned in the question.'.format(i.text)\n",
    "                    template.append(template_01)\n",
    "                elif i.label_ == 'LOC':\n",
    "                    template_01 = 'This location \"{}\" is menthoned in the question.'.format(i.text)\n",
    "                    template.append(template_01)\n",
    "                elif i.label_ == 'DATE' or i.label_ == 'TIME':\n",
    "                    template_01 = 'This timing \"{}\" is menthoned in the question.'.format(i.text)\n",
    "                    template.append(template_01)\n",
    "                else:\n",
    "                    template_01 = 'This entity \"{}\" is menthoned in the question.'.format(i.text)\n",
    "                    template.append(template_01)\n",
    "\n",
    "        else:\n",
    "            template_00 = 'There is no entity mentioned in the question.'\n",
    "            template.append(template_00)\n",
    "\n",
    "        qa['template'] = template\n",
    "        \n",
    "    return one_domain_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f8597df6-fe71-4a69-b9a5-3c8e19a1589b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "industrials dev\n",
      "industrials test\n",
      "consumer test\n",
      "industrials train\n",
      "consumer dev\n",
      "consumer train\n",
      "technology train\n",
      "technology dev\n",
      "technology test\n"
     ]
    }
   ],
   "source": [
    "for file in fileList:\n",
    "    if file[0] != '.':\n",
    "        domain = file.split('_')[1]\n",
    "        t = file.split('_')[2][:-5]\n",
    "        print(domain, t)\n",
    "        f = json.load(open(os.path.join(without_template_path, file)))\n",
    "        withSentiment = generate_entity_template(f)\n",
    "        json.dump(withSentiment, open('Domain_without_duplicate_dataset/entity_template/qa_{}_{}.json'.format(domain, t), 'w', encoding='utf8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d6f874-f563-469e-93e0-096d3995add3",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------\n",
    "\n",
    "### Add Qtype template to domain dataset\n",
    "\n",
    "#### get top 50 words from only three domains: Indus, tech & consumer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a1e8fac6-bb44-45fc-9743-878c575f81f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'qa_dataset_time_sort.json'\n",
    "qa_dataset = json.load(open(path, 'r', encoding='utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "daaaa459-f7a0-4a6c-be34-b2943d85eee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "why_list=[]\n",
    "what_list=[]\n",
    "whyuseful_list = []\n",
    "whatwillhappen_list=[]\n",
    "for qa in qa_dataset:\n",
    "    query = qa['question']\n",
    "    (start, end) = qa['answer']\n",
    "    answer_text = qa['context'][start:end]\n",
    "    context_list = qa['context'].split('. ')\n",
    "    for sentence in context_list:\n",
    "        if answer_text in sentence:\n",
    "            break\n",
    "    if \"What will happen\" in query:\n",
    "        whatwillhappen_list.append(sentence)\n",
    "    elif 'What' in query:\n",
    "        what_list.append(sentence)\n",
    "    elif ('Why' in query) and ('useful' in query):\n",
    "        whyuseful_list.append(sentence)\n",
    "    elif 'Why' in query:\n",
    "        why_list.append(sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7ee935dd-4e49-4ab8-9da4-9bb1018d1dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(dataset):\n",
    "    words = {}\n",
    "    for i in range(len(dataset)):\n",
    "        for word in dataset[i].split():\n",
    "            if word not in words:\n",
    "                words[word]=1\n",
    "            else:\n",
    "                words[word]+=1\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2356f2d-eea7-4d80-9af7-9217cced70dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_wordCounter(words_dict):\n",
    "    # input: a dict of words, key:word, value:times of word shown in the context\n",
    "    # output: a list sorted by the value of dict\n",
    "    a = dict(sorted(words_dict.items(), key=lambda x:x[1], reverse=True))\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "45195515-5c21-487c-9755-4f2663d579e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "why_wordcount = sort_wordCounter(count_words(why_list))\n",
    "what_wordcount = sort_wordCounter(count_words(what_list))\n",
    "whatwillhappen_wordcount = sort_wordCounter(count_words(whatwillhappen_list))\n",
    "whyuseful_wordcount = sort_wordCounter(count_words(whyuseful_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9d950d14-7184-4345-86db-ee5892b9c1f5",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'the': 10134,\n",
       " 'to': 8200,\n",
       " 'and': 6776,\n",
       " 'of': 5766,\n",
       " 'in': 5347,\n",
       " 'a': 4071,\n",
       " 'as': 3187,\n",
       " 'for': 2214,\n",
       " 'its': 2211,\n",
       " 'we': 1993,\n",
       " 'is': 1879,\n",
       " 'that': 1828,\n",
       " 'from': 1683,\n",
       " 'with': 1556,\n",
       " 'on': 1468,\n",
       " 'We': 1325,\n",
       " 'will': 1295,\n",
       " 'are': 1271,\n",
       " 'has': 1197,\n",
       " 'more': 1070,\n",
       " 'growth': 1041,\n",
       " 'be': 1018,\n",
       " 'which': 1012,\n",
       " 'it': 1011,\n",
       " 'by': 984,\n",
       " 'have': 842,\n",
       " 'expect': 833,\n",
       " 'could': 826,\n",
       " 'revenue': 748,\n",
       " 'an': 728,\n",
       " 'our': 707,\n",
       " 'over': 683,\n",
       " 'due': 646,\n",
       " 'or': 645,\n",
       " 'The': 642,\n",
       " 'sales': 612,\n",
       " 'think': 610,\n",
       " 'at': 598,\n",
       " 'this': 592,\n",
       " 'believe': 559,\n",
       " 'demand': 558,\n",
       " 'can': 553,\n",
       " 'market': 551,\n",
       " 'costs': 540,\n",
       " 'operating': 530,\n",
       " 'than': 529,\n",
       " 'company': 524,\n",
       " 'cost': 521,\n",
       " 'new': 519,\n",
       " 'not': 517,\n",
       " 'business': 496,\n",
       " 'also': 479,\n",
       " 'but': 476,\n",
       " 'margins': 459,\n",
       " 'these': 418,\n",
       " 'margin': 416,\n",
       " 'should': 413,\n",
       " 'higher': 404,\n",
       " 'their': 401,\n",
       " 'high': 392,\n",
       " 'would': 391,\n",
       " 'firm': 382,\n",
       " 'share': 379,\n",
       " 'In': 378,\n",
       " 'risk': 378,\n",
       " 'lower': 363,\n",
       " 'customers': 362,\n",
       " 'products': 359,\n",
       " 'because': 353,\n",
       " 'capital': 352,\n",
       " 'product': 351,\n",
       " '2020': 345,\n",
       " 'given': 326,\n",
       " 'likely': 317,\n",
       " 'years': 315,\n",
       " 'strong': 310,\n",
       " 'value': 308,\n",
       " 'forecast': 305,\n",
       " 'other': 304,\n",
       " 'see': 304,\n",
       " 'been': 298,\n",
       " 'next': 295,\n",
       " 'fiscal': 295,\n",
       " 'As': 294,\n",
       " 'increase': 294,\n",
       " 'customer': 292,\n",
       " 'some': 290,\n",
       " 'if': 290,\n",
       " 'pricing': 287,\n",
       " 'However,': 282,\n",
       " 'may': 280,\n",
       " 'continue': 278,\n",
       " 'significant': 275,\n",
       " 'into': 275,\n",
       " 'well': 275,\n",
       " 'industry': 266,\n",
       " 'COVID-19': 265,\n",
       " 'competitive': 262,\n",
       " 'such': 262,\n",
       " 'large': 261,\n",
       " 'through': 261,\n",
       " 'average': 260,\n",
       " 'While': 258,\n",
       " \"company's\": 257,\n",
       " 'result': 255,\n",
       " \"firm's\": 254,\n",
       " '2021': 251,\n",
       " 'about': 249,\n",
       " 'price': 249,\n",
       " 'network': 249,\n",
       " 'prices': 246,\n",
       " 'switching': 244,\n",
       " 'most': 242,\n",
       " 'potential': 239,\n",
       " 'per': 237,\n",
       " 'markets': 235,\n",
       " 'increased': 233,\n",
       " 'they': 231,\n",
       " 'With': 230,\n",
       " 'data': 230,\n",
       " 'so': 223,\n",
       " 'less': 223,\n",
       " 'returns': 220,\n",
       " 'global': 216,\n",
       " 'leverage': 215,\n",
       " 'time': 213,\n",
       " 'up': 212,\n",
       " 'estimate': 209,\n",
       " 'like': 207,\n",
       " 'economic': 207,\n",
       " 'during': 205,\n",
       " 'competition': 204,\n",
       " 'rates': 203,\n",
       " 'low': 201,\n",
       " 'brand': 200,\n",
       " 'lead': 200,\n",
       " 'rate': 199,\n",
       " 'production': 197,\n",
       " 'uncertainty': 195,\n",
       " 'years,': 193,\n",
       " 'pandemic': 193,\n",
       " 'supply': 193,\n",
       " 'remain': 192,\n",
       " 'investment': 191,\n",
       " 'decline': 190,\n",
       " 'leading': 190,\n",
       " 'gross': 189,\n",
       " 'end': 188,\n",
       " 'impact': 186,\n",
       " 'many': 182,\n",
       " 'annual': 182,\n",
       " 'ability': 181,\n",
       " 'consumer': 179,\n",
       " 'around': 178,\n",
       " 'segment': 177,\n",
       " 'increasing': 175,\n",
       " 'all': 171,\n",
       " 'while': 171,\n",
       " 'power': 170,\n",
       " 'assets': 169,\n",
       " 'pressure': 168,\n",
       " 'This': 168,\n",
       " 'was': 167,\n",
       " 'any': 166,\n",
       " 'only': 165,\n",
       " 'billion': 163,\n",
       " 'long-term': 162,\n",
       " 'base': 162,\n",
       " 'services': 160,\n",
       " 'Given': 158,\n",
       " 'capacity': 157,\n",
       " 'scale': 157,\n",
       " 'there': 157,\n",
       " 'recent': 156,\n",
       " 'consumers': 156,\n",
       " 'volume': 155,\n",
       " 'management': 155,\n",
       " 'after': 154,\n",
       " 'one': 153,\n",
       " 'become': 152,\n",
       " 'expansion': 151,\n",
       " 'cash': 151,\n",
       " 'oil': 150,\n",
       " 'software': 150,\n",
       " 'companies': 150,\n",
       " 'advantage': 149,\n",
       " 'profitability': 148,\n",
       " 'spending': 146,\n",
       " 'gas': 146,\n",
       " 'driven': 146,\n",
       " 'able': 146,\n",
       " 'drive': 145,\n",
       " 'competitors': 145,\n",
       " 'five': 144,\n",
       " 'model': 142,\n",
       " 'mix': 142,\n",
       " 'long': 141,\n",
       " 'service': 140,\n",
       " 'fair': 140,\n",
       " 'benefit': 140,\n",
       " '2019': 139,\n",
       " 'do': 138,\n",
       " 'greater': 137,\n",
       " 'levels': 137,\n",
       " 'technology': 136,\n",
       " 'across': 134,\n",
       " 'out': 134,\n",
       " 'operations': 133,\n",
       " 'interest': 133,\n",
       " '2020,': 133,\n",
       " 'financial': 133,\n",
       " 'even': 132,\n",
       " 'return': 131,\n",
       " 'since': 131,\n",
       " 'further': 131,\n",
       " 'development': 130,\n",
       " 'acquisition': 130,\n",
       " 'very': 130,\n",
       " 'both': 129,\n",
       " 'near': 129,\n",
       " 'shift': 129,\n",
       " 'regulatory': 128,\n",
       " 'grow': 128,\n",
       " 'where': 127,\n",
       " 'portfolio': 127,\n",
       " 'year': 126,\n",
       " 'continues': 125,\n",
       " 'better': 124,\n",
       " 'If': 124,\n",
       " 'toward': 124,\n",
       " 'solutions': 124,\n",
       " 'use': 123,\n",
       " 'increases': 123,\n",
       " 'need': 123,\n",
       " 'difficult': 122,\n",
       " 'maintain': 122,\n",
       " 'retail': 121,\n",
       " 'anticipate': 121,\n",
       " 'future': 120,\n",
       " 'small': 120,\n",
       " 'travel': 120,\n",
       " 'offset': 119,\n",
       " 'distribution': 119,\n",
       " 'past': 119,\n",
       " 'net': 118,\n",
       " 'project': 116,\n",
       " 'term': 116,\n",
       " 'results': 115,\n",
       " 'For': 114,\n",
       " 'resulting': 114,\n",
       " 'total': 113,\n",
       " 'larger': 113,\n",
       " 'access': 113,\n",
       " 'expand': 113,\n",
       " 'relatively': 112,\n",
       " 'digital': 112,\n",
       " 'much': 112,\n",
       " 'growing': 111,\n",
       " 'benefits': 111,\n",
       " 'credit': 111,\n",
       " 'make': 111,\n",
       " 'performance': 110,\n",
       " 'equipment': 110,\n",
       " 'two': 110,\n",
       " 'growth,': 109,\n",
       " 'increasingly': 109,\n",
       " 'risks': 109,\n",
       " 'take': 109,\n",
       " 'between': 109,\n",
       " 'still': 109,\n",
       " 'additional': 108,\n",
       " 'key': 108,\n",
       " 'line': 107,\n",
       " 'overall': 106,\n",
       " 'several': 105,\n",
       " 'Additionally,': 105,\n",
       " '2021,': 105,\n",
       " 'faces': 104,\n",
       " 'improve': 104,\n",
       " 'position': 103,\n",
       " 'view': 103,\n",
       " 'back': 103,\n",
       " 'peers': 103,\n",
       " 'asset': 103,\n",
       " 'Although': 102,\n",
       " 'smaller': 102,\n",
       " 'costs,': 102,\n",
       " 'including': 102,\n",
       " 'earnings': 102,\n",
       " 'come': 101,\n",
       " 'particularly': 101,\n",
       " 'online': 101,\n",
       " 'few': 101,\n",
       " 'gains': 101,\n",
       " 'business,': 101,\n",
       " 'longer': 100,\n",
       " 'adjusted': 100,\n",
       " 'no': 100,\n",
       " 'when': 100,\n",
       " 'roughly': 99,\n",
       " 'limited': 99,\n",
       " 'basis': 98,\n",
       " 'part': 98,\n",
       " 'million': 98,\n",
       " 'bank': 98,\n",
       " \"don't\": 98,\n",
       " 'exposure': 97,\n",
       " 'coronavirus': 96,\n",
       " 'reduce': 96,\n",
       " 'improved': 95,\n",
       " 'existing': 95,\n",
       " 'led': 95,\n",
       " 'users': 95,\n",
       " 'nature': 95,\n",
       " 'market,': 95,\n",
       " 'face': 95,\n",
       " 'highly': 94,\n",
       " 'term,': 94,\n",
       " 'those': 94,\n",
       " 'brands': 94,\n",
       " 'provide': 93,\n",
       " 'support': 93,\n",
       " 'lack': 93,\n",
       " 'expected': 93,\n",
       " 'rise': 93,\n",
       " 'declines': 92,\n",
       " 'investments': 92,\n",
       " 'volumes': 92,\n",
       " 'generate': 92,\n",
       " 'does': 91,\n",
       " 'store': 91,\n",
       " 'profit': 91,\n",
       " 'environment': 91,\n",
       " 'acquisitions': 91,\n",
       " 'under': 90,\n",
       " 'businesses': 90,\n",
       " 'often': 90,\n",
       " 'within': 90,\n",
       " 'assume': 90,\n",
       " 'markets,': 90,\n",
       " 'international': 89,\n",
       " 'largely': 89,\n",
       " 'were': 89,\n",
       " 'rising': 89,\n",
       " 'number': 89,\n",
       " 'core': 89,\n",
       " 'Our': 89,\n",
       " 'focus': 89,\n",
       " 'organic': 88,\n",
       " 'marketing': 88,\n",
       " 'unit': 87,\n",
       " 'top': 87,\n",
       " 'firms': 87,\n",
       " 'down': 87,\n",
       " 'help': 87,\n",
       " 'security': 87,\n",
       " 'thus': 87,\n",
       " 'changes': 86,\n",
       " 'stores': 86,\n",
       " 'major': 85,\n",
       " 'commercial': 85,\n",
       " 'thanks': 85,\n",
       " 'platform': 85,\n",
       " 'opportunities': 84,\n",
       " 'rating': 84,\n",
       " 'being': 84,\n",
       " 'cloud': 84,\n",
       " 'points': 83,\n",
       " 'period': 83,\n",
       " 'level': 83,\n",
       " 'near-term': 82,\n",
       " 'natural': 82,\n",
       " 'invested': 82,\n",
       " 'losses': 82,\n",
       " 'significantly': 82,\n",
       " 'medium': 82,\n",
       " 'Because': 81,\n",
       " 'fall': 81,\n",
       " 'Further,': 81,\n",
       " 'material': 81,\n",
       " 'current': 81,\n",
       " 'remains': 80,\n",
       " 'products,': 80,\n",
       " 'government': 80,\n",
       " 'incremental': 80,\n",
       " 'manufacturing': 80,\n",
       " 'equity': 80,\n",
       " 'strategy': 80,\n",
       " 'half': 80,\n",
       " 'excess': 80,\n",
       " 'premium': 79,\n",
       " 'attractive': 79,\n",
       " 'substantial': 79,\n",
       " 'first': 79,\n",
       " 'providers': 78,\n",
       " 'offer': 78,\n",
       " '2022': 77,\n",
       " 'A': 77,\n",
       " 'require': 77,\n",
       " 'negative': 77,\n",
       " 'cause': 77,\n",
       " 'expenses': 77,\n",
       " 'switch': 77,\n",
       " 'pandemic,': 77,\n",
       " 'clients': 77,\n",
       " 'already': 76,\n",
       " 'needs': 76,\n",
       " 'ongoing': 76,\n",
       " 'debt': 76,\n",
       " 'income': 76,\n",
       " 'own': 76,\n",
       " 'industrial': 75,\n",
       " 'keep': 75,\n",
       " 'content': 75,\n",
       " 'making': 74,\n",
       " 'recovery': 74,\n",
       " 'typically': 74,\n",
       " 'efficiency': 74,\n",
       " 'related': 73,\n",
       " 'profits': 73,\n",
       " 'above': 73,\n",
       " 'reducing': 73,\n",
       " 'continued': 72,\n",
       " 'now': 72,\n",
       " 'below': 72,\n",
       " 'space': 72,\n",
       " 'volatility': 71,\n",
       " 'percentage': 71,\n",
       " 'EBITDA': 71,\n",
       " 'generally': 71,\n",
       " 'experience': 71,\n",
       " 'wireless': 71,\n",
       " 'had': 71,\n",
       " 'offerings': 70,\n",
       " 'flow': 70,\n",
       " 'efforts': 70,\n",
       " 'create': 70,\n",
       " 'system': 70,\n",
       " 'insurance': 70,\n",
       " 'ad': 70,\n",
       " 'retailers': 69,\n",
       " 'affect': 69,\n",
       " 'research': 69,\n",
       " 'nearly': 69,\n",
       " 'same': 69,\n",
       " 'portion': 69,\n",
       " 'primarily': 69,\n",
       " 'compared': 68,\n",
       " 'three': 68,\n",
       " 'makes': 68,\n",
       " 'little': 68,\n",
       " 'historically': 68,\n",
       " 'relative': 68,\n",
       " 'slightly': 67,\n",
       " 'another': 67,\n",
       " 'meaningful': 67,\n",
       " 'change': 67,\n",
       " 'robust': 67,\n",
       " 'expense': 67,\n",
       " 'contracts': 67,\n",
       " 'especially': 67,\n",
       " 'modest': 67,\n",
       " 'improvement': 67,\n",
       " 'decade': 67,\n",
       " 'made': 67,\n",
       " 'e-commerce': 67,\n",
       " 'food': 67,\n",
       " 'each': 66,\n",
       " 'vehicle': 66,\n",
       " 'loss': 66,\n",
       " 'categories': 66,\n",
       " 'trends': 66,\n",
       " 'players': 65,\n",
       " 'disruption': 65,\n",
       " 'energy': 65,\n",
       " 'off': 65,\n",
       " 'process': 65,\n",
       " 'along': 65,\n",
       " 'local': 64,\n",
       " 'Internet': 64,\n",
       " 'relationships': 63,\n",
       " 'among': 63,\n",
       " 'health': 63,\n",
       " 'balance': 63,\n",
       " 'traffic': 63,\n",
       " 'entry': 63,\n",
       " 'favorable': 62,\n",
       " 'build': 62,\n",
       " 'quality': 62,\n",
       " '2025': 62,\n",
       " 'multiple': 62,\n",
       " 'fixed': 62,\n",
       " 'terms': 62,\n",
       " 'once': 61,\n",
       " 'largest': 61,\n",
       " 'China': 61,\n",
       " 'outlook': 61,\n",
       " 'user': 61,\n",
       " 'tend': 61,\n",
       " 'design': 61,\n",
       " 'reduced': 61,\n",
       " 'chain': 61,\n",
       " '10%': 60,\n",
       " 'last': 60,\n",
       " 'traditional': 60,\n",
       " 'different': 60,\n",
       " 'industry,': 60,\n",
       " 'networks': 60,\n",
       " '&': 60,\n",
       " 'allow': 60,\n",
       " 'important': 60,\n",
       " 'intangible': 60,\n",
       " 'based': 59,\n",
       " 'despite': 59,\n",
       " 'coming': 59,\n",
       " 'infrastructure': 59,\n",
       " 'mobile': 59,\n",
       " 'effect': 58,\n",
       " 'penetration': 58,\n",
       " 'potentially': 58,\n",
       " 'addition': 57,\n",
       " 'associated': 57,\n",
       " 'away': 57,\n",
       " 'them': 57,\n",
       " 'Furthermore,': 57,\n",
       " 'social': 57,\n",
       " 'advantages': 57,\n",
       " 'driving': 56,\n",
       " 'customers,': 56,\n",
       " 'suppliers': 56,\n",
       " 'segment,': 56,\n",
       " 'solid': 56,\n",
       " 'After': 56,\n",
       " 'before': 56,\n",
       " 'presence': 56,\n",
       " 'order': 56,\n",
       " 'compound': 56,\n",
       " 'emerging': 56,\n",
       " 'pay': 56,\n",
       " 'then': 56,\n",
       " 'offering': 56,\n",
       " 'example,': 56,\n",
       " 'currently': 56,\n",
       " 'unlikely': 56,\n",
       " 'cycle': 55,\n",
       " 'economy': 55,\n",
       " 'revenue,': 55,\n",
       " 'versus': 55,\n",
       " 'positive': 55,\n",
       " 'safety': 55,\n",
       " 'time,': 55,\n",
       " 'enterprise': 55,\n",
       " '10': 55,\n",
       " 'Also,': 55,\n",
       " 'reach': 55,\n",
       " 'early': 55,\n",
       " 'sales,': 54,\n",
       " 'integrated': 54,\n",
       " 'resulted': 54,\n",
       " 'drug': 54,\n",
       " 'becomes': 54,\n",
       " 'addition,': 54,\n",
       " 'fuel': 54,\n",
       " 'room': 54,\n",
       " 'barriers': 54,\n",
       " 'quarter': 53,\n",
       " 'amount': 53,\n",
       " 'leads': 53,\n",
       " 'banks': 53,\n",
       " 'single': 53,\n",
       " 'slow': 53,\n",
       " 'public': 53,\n",
       " 'though': 53,\n",
       " 'rather': 52,\n",
       " 'savings': 52,\n",
       " 'home': 52,\n",
       " 'segments': 52,\n",
       " 'failure': 52,\n",
       " 'work': 52,\n",
       " 'five-year': 52,\n",
       " 'Finally,': 52,\n",
       " 'legacy': 52,\n",
       " 'downturn': 52,\n",
       " 'size': 52,\n",
       " 'ESG': 52,\n",
       " 'set': 51,\n",
       " 'expanding': 51,\n",
       " 'systems': 51,\n",
       " 'These': 51,\n",
       " 'various': 51,\n",
       " 'IT': 51,\n",
       " 'American': 51,\n",
       " 'generation': 51,\n",
       " 'gain': 50,\n",
       " 'drop': 50,\n",
       " 'throughout': 50,\n",
       " 'plans': 50,\n",
       " 'pipeline': 50,\n",
       " \"bank's\": 50,\n",
       " 'combined': 50,\n",
       " 'effects': 50,\n",
       " 'move': 50,\n",
       " 'materially': 49,\n",
       " 'trading': 49,\n",
       " 'raising': 49,\n",
       " 'creating': 49,\n",
       " 'trend': 49,\n",
       " 'projects': 49,\n",
       " 'vendors': 49,\n",
       " 'commodity': 49,\n",
       " 'profitable': 49,\n",
       " 'restaurant': 48,\n",
       " 'headwinds': 48,\n",
       " 'sensitive': 48,\n",
       " 'real': 48,\n",
       " 'lost': 48,\n",
       " 'having': 48,\n",
       " 'cyclical': 48,\n",
       " 'inventory': 48,\n",
       " 'view,': 48,\n",
       " 'healthy': 48,\n",
       " 'category': 48,\n",
       " 'reputation': 48,\n",
       " 'margins,': 48,\n",
       " 'center': 48,\n",
       " 'aircraft': 48,\n",
       " 'stemming': 48,\n",
       " 'source': 48,\n",
       " 'using': 47,\n",
       " 'invest': 47,\n",
       " 'develop': 47,\n",
       " 'control': 47,\n",
       " 'critical': 47,\n",
       " 'exposed': 47,\n",
       " '20%': 47,\n",
       " 'heavily': 47,\n",
       " 'caused': 47,\n",
       " 'advertising': 47,\n",
       " 'meet': 47,\n",
       " 'carriers': 47,\n",
       " 'operational': 46,\n",
       " 'midcycle': 46,\n",
       " 'provides': 46,\n",
       " 'required': 46,\n",
       " 'following': 46,\n",
       " 'investors': 46,\n",
       " 'On': 46,\n",
       " 'explicit': 46,\n",
       " 'purchase': 46,\n",
       " 'find': 46,\n",
       " 'construction': 46,\n",
       " 'times': 46,\n",
       " 'enough': 46,\n",
       " 'North': 46,\n",
       " 'raise': 46,\n",
       " 'risk,': 46,\n",
       " 'execution': 45,\n",
       " 'recently': 45,\n",
       " 'available': 45,\n",
       " 'expenditures': 45,\n",
       " 'adoption': 45,\n",
       " '(which': 45,\n",
       " 'ratio': 45,\n",
       " 'allows': 45,\n",
       " 'demand,': 45,\n",
       " 'must': 45,\n",
       " 'similar': 45,\n",
       " 'flows': 45,\n",
       " 'represents': 45,\n",
       " 'however,': 45,\n",
       " 'carbon': 45,\n",
       " 'fewer': 44,\n",
       " 'competing': 44,\n",
       " '2019,': 44,\n",
       " 'via': 44,\n",
       " 'tied': 44,\n",
       " 'allowed': 44,\n",
       " 'base,': 44,\n",
       " 'consolidation': 44,\n",
       " 'supplier': 44,\n",
       " 'client': 44,\n",
       " 'delivery': 44,\n",
       " 'heavy': 44,\n",
       " \"management's\": 43,\n",
       " 'boost': 43,\n",
       " 'run': 43,\n",
       " 'attract': 43,\n",
       " 'helped': 43,\n",
       " 'used': 43,\n",
       " 'ultimately': 43,\n",
       " 'elevated': 43,\n",
       " 'selling': 43,\n",
       " 'crisis': 43,\n",
       " 'concerns': 43,\n",
       " 'strength': 43,\n",
       " 'although': 43,\n",
       " 'compete': 43,\n",
       " 'prices,': 43,\n",
       " 'means': 43,\n",
       " 'platform,': 42,\n",
       " 'years.': 42,\n",
       " 'growth.': 42,\n",
       " '30%': 42,\n",
       " 'turn': 42,\n",
       " 'target': 42,\n",
       " 'steady': 42,\n",
       " 'It': 42,\n",
       " 'manufacturers': 42,\n",
       " 'national': 42,\n",
       " 'rebound': 42,\n",
       " 'faster': 42,\n",
       " 'gaming': 42,\n",
       " 'closures': 41,\n",
       " 'top-line': 41,\n",
       " 'might': 41,\n",
       " 'Since': 41,\n",
       " 'corporate': 41,\n",
       " '7%': 41,\n",
       " 'until': 41,\n",
       " 'year,': 41,\n",
       " 'factors': 41,\n",
       " 'applications': 41,\n",
       " 'partially': 41,\n",
       " '40%': 41,\n",
       " 'challenges': 41,\n",
       " 'too': 41,\n",
       " 'results,': 41,\n",
       " 'fee': 41,\n",
       " 'reduction': 41,\n",
       " 'fiber': 41,\n",
       " 'That': 41,\n",
       " 'deliver': 40,\n",
       " 'drives': 40,\n",
       " 'beyond': 40,\n",
       " 'storage': 40,\n",
       " 'parts': 40,\n",
       " 'automotive': 40,\n",
       " 'secular': 40,\n",
       " 'developing': 40,\n",
       " 'chip': 40,\n",
       " 'against': 40,\n",
       " 'defense': 40,\n",
       " 'pace': 40,\n",
       " 'areas': 40,\n",
       " 'weigh': 40,\n",
       " 'expertise': 40,\n",
       " 'direct': 40,\n",
       " 'opportunity': 40,\n",
       " 'acquired': 40,\n",
       " 'issues': 40,\n",
       " 'offers': 39,\n",
       " 'contract': 39,\n",
       " 'periods': 39,\n",
       " 'goods': 39,\n",
       " 'drugs': 39,\n",
       " 'life': 39,\n",
       " 'banking': 39,\n",
       " 'innovation': 39,\n",
       " 'how': 39,\n",
       " 'developed': 39,\n",
       " 'volatile': 39,\n",
       " 'channel': 39,\n",
       " 'costs.': 39,\n",
       " 'therefore': 39,\n",
       " 'provider': 39,\n",
       " 'competitor': 39,\n",
       " 'synergies': 39,\n",
       " 'certain': 39,\n",
       " 'shifts': 39,\n",
       " 'account': 39,\n",
       " 'inflation': 39,\n",
       " 'possible': 38,\n",
       " 'close': 38,\n",
       " 'money': 38,\n",
       " 'footprint': 38,\n",
       " 'Overall,': 38,\n",
       " '5%': 38,\n",
       " 'annually': 38,\n",
       " 'mostly': 38,\n",
       " 'forced': 38,\n",
       " 'creates': 38,\n",
       " 'threat': 38,\n",
       " 'mid-single-digit': 38,\n",
       " 'tax': 38,\n",
       " 'Even': 38,\n",
       " 'sold': 38,\n",
       " 'third': 38,\n",
       " 'retain': 38,\n",
       " 'R&D': 38,\n",
       " 'Over': 38,\n",
       " '50%': 38,\n",
       " 'components': 38,\n",
       " 'low-single-digit': 38,\n",
       " 'steel': 38,\n",
       " 'generic': 38,\n",
       " 'integration': 38,\n",
       " 'either': 38,\n",
       " 'regulators': 38,\n",
       " 'spread': 37,\n",
       " 'structure': 37,\n",
       " 'scale,': 37,\n",
       " 'alternative': 37,\n",
       " 'housing': 37,\n",
       " 'producers': 37,\n",
       " 'platforms': 37,\n",
       " 'primary': 37,\n",
       " 'resources': 37,\n",
       " 'providing': 37,\n",
       " 'Canadian': 37,\n",
       " 'declining': 37,\n",
       " 'side': 37,\n",
       " 'just': 37,\n",
       " 'get': 37,\n",
       " 'water': 37,\n",
       " 'partners': 37,\n",
       " 'weak': 37,\n",
       " 'enterprises': 37,\n",
       " 'said,': 37,\n",
       " 'competition,': 36,\n",
       " 'seen': 36,\n",
       " 'point': 36,\n",
       " 'sustainable': 36,\n",
       " 'processing': 36,\n",
       " 'spend': 36,\n",
       " 'vehicles': 36,\n",
       " 'focused': 36,\n",
       " 'medical': 36,\n",
       " 'capabilities': 36,\n",
       " 'installed': 36,\n",
       " 'macroeconomic': 36,\n",
       " 'maintenance': 36,\n",
       " 'sell': 36,\n",
       " 'subject': 36,\n",
       " 'healthcare': 36,\n",
       " 'third-party': 36,\n",
       " 'domestic': 36,\n",
       " 'labor': 36,\n",
       " 'locations': 35,\n",
       " 'operators': 35,\n",
       " 'structural': 35,\n",
       " 'generated': 35,\n",
       " '4%': 35,\n",
       " 'capital,': 35,\n",
       " 'range': 35,\n",
       " 'effective': 35,\n",
       " 'far': 35,\n",
       " '6%': 35,\n",
       " 'technological': 35,\n",
       " 'assumptions': 35,\n",
       " 'Due': 35,\n",
       " 'clinical': 35,\n",
       " 'without': 35,\n",
       " 'cannot': 35,\n",
       " 'effectively': 35,\n",
       " 'normalized': 35,\n",
       " 'acquisitions,': 35,\n",
       " 'majority': 35,\n",
       " 'region': 35,\n",
       " 'vaccine': 35,\n",
       " 'sheet': 35,\n",
       " 'put': 35,\n",
       " 'building': 35,\n",
       " 'payment': 35,\n",
       " 'falling': 35,\n",
       " 'tools': 35,\n",
       " 'governance': 35,\n",
       " 'availability': 34,\n",
       " 'facilities': 34,\n",
       " 'directly': 34,\n",
       " '8%': 34,\n",
       " 'estate': 34,\n",
       " 'Despite': 34,\n",
       " 'efficient': 34,\n",
       " 'recover': 34,\n",
       " 'good': 34,\n",
       " 'patients': 34,\n",
       " '2%': 34,\n",
       " 'success': 34,\n",
       " 'ensure': 34,\n",
       " 'give': 34,\n",
       " 'operate': 34,\n",
       " 'bring': 34,\n",
       " '2024': 34,\n",
       " 'produce': 34,\n",
       " 'digits': 34,\n",
       " 'function': 34,\n",
       " 'massive': 34,\n",
       " 'historical': 34,\n",
       " 'peers,': 34,\n",
       " 'competitors,': 34,\n",
       " 'period,': 34,\n",
       " 'hurt': 34,\n",
       " 'accelerate': 33,\n",
       " 'moving': 33,\n",
       " 'result,': 33,\n",
       " '2018': 33,\n",
       " 'fleet': 33,\n",
       " 'coal': 33,\n",
       " 'EPS': 33,\n",
       " 'outside': 33,\n",
       " 'business.': 33,\n",
       " 'achieve': 33,\n",
       " 'partner': 33,\n",
       " 'becoming': 33,\n",
       " 'Still,': 33,\n",
       " 'license': 33,\n",
       " 'improving': 33,\n",
       " 'But': 33,\n",
       " 'least': 33,\n",
       " 'exchange': 33,\n",
       " 'electric': 33,\n",
       " 'economies': 33,\n",
       " 'services,': 33,\n",
       " 'helps': 33,\n",
       " 'rates,': 33,\n",
       " 'fees': 33,\n",
       " 'way': 33,\n",
       " 'share,': 33,\n",
       " 'temporary': 33,\n",
       " 'COVID-19,': 33,\n",
       " 'administrative': 33,\n",
       " 'properties': 33,\n",
       " '(as': 33,\n",
       " 'Amazon': 32,\n",
       " 'conditions': 32,\n",
       " 'helping': 32,\n",
       " 'allowing': 32,\n",
       " 'eventually': 32,\n",
       " 'regulations': 32,\n",
       " 'aggressive': 32,\n",
       " 'approximately': 32,\n",
       " 'push': 32,\n",
       " 'itself': 32,\n",
       " 'data,': 32,\n",
       " 'utilization': 32,\n",
       " 'combination': 32,\n",
       " 'mission-critical': 32,\n",
       " 'quite': 32,\n",
       " '5G': 32,\n",
       " 'built': 32,\n",
       " '2025,': 32,\n",
       " 'stronger': 32,\n",
       " 'assets,': 32,\n",
       " 'emissions': 32,\n",
       " 'sector': 31,\n",
       " 'almost': 31,\n",
       " 'outbreak': 31,\n",
       " 'private': 31,\n",
       " 'earn': 31,\n",
       " 'look': 31,\n",
       " 'crude': 31,\n",
       " 'usage': 31,\n",
       " 'deal': 31,\n",
       " 'stock': 31,\n",
       " 'pressures': 31,\n",
       " 'declined': 31,\n",
       " 'rapid': 31,\n",
       " 'hold': 31,\n",
       " 'enter': 31,\n",
       " '3%': 31,\n",
       " 'challenging': 31,\n",
       " 'quickly': 31,\n",
       " 'cut': 31,\n",
       " 'improvements': 31,\n",
       " 'positioned': 31,\n",
       " 'technologies': 31,\n",
       " 'distributors': 31,\n",
       " 'weaker': 31,\n",
       " 'limit': 31,\n",
       " 'stay': 31,\n",
       " 'America': 31,\n",
       " 'extended': 31,\n",
       " 'include': 31,\n",
       " 'spending,': 31,\n",
       " 'European': 31,\n",
       " \"We're\": 31,\n",
       " 'ahead': 30,\n",
       " 'struggle': 30,\n",
       " 'decrease': 30,\n",
       " 'programs': 30,\n",
       " 'purchasing': 30,\n",
       " 'generates': 30,\n",
       " 'estimates': 30,\n",
       " 'levels,': 30,\n",
       " 'add': 30,\n",
       " 'second': 30,\n",
       " 'loyalty': 30,\n",
       " 'capture': 30,\n",
       " 'flat': 30,\n",
       " 'assign': 30,\n",
       " 'apparel': 30,\n",
       " 'rely': 30,\n",
       " 'expensive': 30,\n",
       " 'recurring': 30,\n",
       " 'causing': 30,\n",
       " 'retention': 30,\n",
       " 'orders': 30,\n",
       " 'fully': 30,\n",
       " 'hardware': 30,\n",
       " 'productivity': 30,\n",
       " ...}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "why_wordcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ba7bd4ac-ffa6-4933-8936-0e92f7ec3b17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmi(wordCount):\n",
    "    pmi_dict = {}\n",
    "    for word in wordCount:\n",
    "        if wordCount[word]<200:\n",
    "            break\n",
    "        else:\n",
    "            num_word = 0\n",
    "            if word in why_wordcount:\n",
    "                num_word += why_wordcount[word]\n",
    "            if word in what_wordcount:\n",
    "                num_word += what_wordcount[word]\n",
    "            if word in whyuseful_wordcount:\n",
    "                num_word += whyuseful_wordcount[word]\n",
    "            if word in whatwillhappen_wordcount:\n",
    "                num_word += whatwillhappen_wordcount[word]\n",
    "            # p_word = num_word / (sum(why_wordcount.values())+sum(what_wordcount.values())+sum(whyuseful_wordcount.values())+sum(whatwillhappen_wordcount.values()))\n",
    "            # conditional_p_word = wordCount[word] / sum(wordCount.values())\n",
    "            p_word = num_word / (len(why_wordcount)+len(what_wordcount)+len(whyuseful_wordcount)+len(whatwillhappen_wordcount))\n",
    "            conditional_p_word = wordCount[word]/len(wordCount)\n",
    "            \n",
    "            pmi_dict[word] = np.log(conditional_p_word/p_word)\n",
    "    \n",
    "    return pmi_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db676deb-66ab-4f29-835e-810cf63093b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top50_prompt_words(why_wordcount):    \n",
    "    #input: word count dict\n",
    "    #output: top 50 prompt word list of corresponds to the word count\n",
    "    why_word_pmiDict = pmi(why_wordcount) \n",
    "    sort_why_pmi = sort_wordCounter(why_word_pmiDict)\n",
    "    top50_whyPromptWords_list = list(sort_why_pmi)[0:50]\n",
    "    return top50_whyPromptWords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "245d74dd-9768-4b32-914f-f86b66f31927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why: 50\n",
      "What: 50\n",
      "Why useful: 50\n",
      "What will happen: 50\n"
     ]
    }
   ],
   "source": [
    "top50_whyPromptWords_list = get_top50_prompt_words(why_wordcount)\n",
    "top50_whatPromptWords_list = get_top50_prompt_words(what_wordcount)\n",
    "top50_whyusefulPromptWords_list = get_top50_prompt_words(whyuseful_wordcount)\n",
    "top50_whatwillhappenPromptWords_list = get_top50_prompt_words(whatwillhappen_wordcount)\n",
    "print('Why:',len(top50_whyPromptWords_list))\n",
    "print('What:',len(top50_whatPromptWords_list))\n",
    "print('Why useful:',len(top50_whyusefulPromptWords_list))\n",
    "print('What will happen:',len(top50_whatwillhappenPromptWords_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "664a5c63-fa22-41e8-8fae-958b4a155ae9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['should',\n",
       " 'capital',\n",
       " 'through',\n",
       " \"company's\",\n",
       " \"firm's\",\n",
       " 'While',\n",
       " 'competitive',\n",
       " 'which',\n",
       " 'some',\n",
       " 'think',\n",
       " 'products',\n",
       " 'The',\n",
       " 'believe',\n",
       " 'network',\n",
       " 'firm',\n",
       " 'other',\n",
       " 'its',\n",
       " 'cost',\n",
       " 'it',\n",
       " 'customers',\n",
       " 'such',\n",
       " 'strong',\n",
       " 'has',\n",
       " 'market',\n",
       " 'by',\n",
       " 'also',\n",
       " 'business',\n",
       " 'company',\n",
       " 'can',\n",
       " 'but',\n",
       " 'with',\n",
       " 'product',\n",
       " 'on',\n",
       " 'and',\n",
       " 'In',\n",
       " 'new',\n",
       " 'customer',\n",
       " 'more',\n",
       " 'that',\n",
       " 'pricing',\n",
       " 'their',\n",
       " 'this',\n",
       " 'will',\n",
       " 'the',\n",
       " 'growth',\n",
       " 'into',\n",
       " 'for',\n",
       " 'next',\n",
       " 'We',\n",
       " 'sales']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top50_whatPromptWords_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f2a07a93-6017-43f4-b60d-03889af6c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_Qtype_template(qa_dataset):\n",
    "    # Random given prompt word for Qtype\n",
    "\n",
    "    for qa in qa_dataset:\n",
    "        query = qa['question']\n",
    "        (start, end) = qa['answer']\n",
    "        answer_text = qa['context'][start:end]\n",
    "        context_list = qa['context'].split('. ')\n",
    "        for sentence in context_list:\n",
    "            if answer_text in sentence:\n",
    "                break\n",
    "\n",
    "    #     # question type\n",
    "\n",
    "        if \"What will happen\" in query:\n",
    "            template_01 = 'To answer a \"What will happen\" question, you need to look for \"{}\"'.format(top50_whatwillhappenPromptWords_list[random.randint(0,len(top50_whatwillhappenPromptWords_list)-1)])   \n",
    "        elif 'What' in query:\n",
    "            template_01 = 'To answer a \"What\" question, you need to look for \"{}\"'.format(top50_whatPromptWords_list[random.randint(0,len(top50_whatPromptWords_list)-1)])   \n",
    "        elif ('Why' in query) and ('useful' in query):\n",
    "            template_01 = 'To answer a \"Why useful\" question, you need to look for \"{}\"'.format(top50_whyusefulPromptWords_list[random.randint(0,len(top50_whyusefulPromptWords_list)-1)])   \n",
    "        elif 'Why' in query:\n",
    "            template_01 = 'To answer a \"Why\" question, you need to look for \"{}\"'.format(top50_whyPromptWords_list[random.randint(0,len(top50_whyPromptWords_list)-1)])   \n",
    "\n",
    "        template = [template_01,]\n",
    "    \n",
    "        qa['template'] = template\n",
    "    \n",
    "    return qa_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c1ec7930-4586-48c0-90dd-8f10f99aaf02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "technology train\n",
      "industrials dev\n",
      "industrials test\n",
      "technology dev\n",
      "technology test\n",
      "healthcare test\n",
      "healthcare dev\n",
      "consumer test\n",
      "healthcare train\n",
      "industrials train\n",
      "consumer dev\n",
      "consumer train\n"
     ]
    }
   ],
   "source": [
    "for file in fileList:\n",
    "    if file[0] != '.':\n",
    "        domain = file.split('_')[1]\n",
    "        t = file.split('_')[2][:-5]\n",
    "        print(domain, t)\n",
    "        f = json.load(open(os.path.join(without_template_path, file)))\n",
    "        withSentiment = generate_Qtype_template(f)\n",
    "        json.dump(withSentiment, open('Domain_without_duplicate_dataset/Qtype_template/qa_{}_{}.json'.format(domain, t), 'w', encoding='utf8'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eacbbab3-64da-4741-a066-4d743b02b35b",
   "metadata": {},
   "source": [
    "# ------------------------------\n",
    "\n",
    "# Add empty template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a142a5-ee4b-4838-87a8-5fdc0e7c64d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "06daf522-4469-4f8a-a9fa-f6beae829f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_empty_template_for_domain(qa_dataset):\n",
    "\n",
    "    for qa in qa_dataset:\n",
    "    \n",
    "        qa['template'] = ' '\n",
    "    \n",
    "    return qa_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8174cf05-f3b9-452a-b4a6-b00c5f5a49f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "industrials dev\n",
      "industrials test\n",
      "consumer test\n",
      "industrials train\n",
      "consumer dev\n",
      "consumer train\n",
      "technology train\n",
      "technology dev\n",
      "technology test\n"
     ]
    }
   ],
   "source": [
    "for file in fileList:\n",
    "    if file[0] != '.':\n",
    "        domain = file.split('_')[1]\n",
    "        t = file.split('_')[2][:-5]\n",
    "        print(domain, t)\n",
    "        f = json.load(open(os.path.join(without_template_path, file)))\n",
    "        withSentiment = generate_empty_template_for_domain(f)\n",
    "        json.dump(withSentiment, open('Domain_without_duplicate_dataset/no_template/qa_{}_{}.json'.format(domain, t), 'w', encoding='utf8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a31b07ba-0e14-4f40-943d-7772789b1d29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.069999999999993"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "75.33-73.26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5dd8782c-8a44-476c-a47a-edce900760e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1699999999999946"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "37.66-34.49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5d58dbe-f6d5-41df-9511-37e9458769c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.14000000000000057"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "61.42-61.28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeda4b52-c431-4e3a-b40e-1c2ddc4b33ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
